# Description

This is a CNN model built using Keras and trained on a image set from kaggle to identify images of sign language and transpose them into text. 

Included is a formal proposal letter to a fictitious school and a technical document that includes a development cycle and methodology.

I also used various python libraries like scikit-learn, seaborn, and numpy to create visualizations about the model and it's training. 

## Origins

I am lucky enough to have worked with a diverse special needs population for a few years. This included friends from 4 years old all the way to 26. One of the most overseen areas for the special needs population is flexible communication. Many augmentiative and alternate forms of communication (AAC) exist, and although sometimes not affordable, have become adaptable to near any need.

One major pitfall, and what this project was based on, is how difficult it can be to communicate between alternate mediums. I picture one student who can sign fluently, and another who uses eye-gaze. Both students have nearly identical interests, movies, games, music, anything! But they can only communicate when the ASL translator is available.

I wanted this project to represent the possibilities AI opens up when developing new ways for friends who use AAC.